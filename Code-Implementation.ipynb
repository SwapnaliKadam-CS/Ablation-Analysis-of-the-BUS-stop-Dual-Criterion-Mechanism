{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10dd903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 1: SETUP AND INSTALLATION\n",
    "import os\n",
    "\n",
    "# 1. Force TensorFlow to use Legacy Keras (Critical for BERT)\n",
    "os.environ['TF_USE_LEGACY_KERAS'] = '1'\n",
    "\n",
    "# 2. Clone Repository\n",
    "if not os.path.exists(\"BUS-stop\"):\n",
    "    print(\"Cloning Repository...\")\n",
    "    !git clone https://github.com/DMCB-GIST/BUS-stop.git\n",
    "else:\n",
    "    print(\"Repo already exists.\")\n",
    "\n",
    "# 3. Enter Directory\n",
    "%cd /content/BUS-stop/bus-stop-keras\n",
    "\n",
    "# 4. Install Dependencies\n",
    "print(\"Installing Libraries...\")\n",
    "!pip install -q tensorflow tf_keras\n",
    "!pip install -q transformers==4.44.0 scikit-learn pandas sentencepiece datasets\n",
    "\n",
    "# 5. Fix Model Downloads (Force fresh download)\n",
    "print(\"Downloading BERT Model files...\")\n",
    "!rm -rf params/bert_base\n",
    "!mkdir -p params/bert_base\n",
    "!wget -q -O params/bert_base/pytorch_model.bin https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin\n",
    "!wget -q -O params/bert_base/config.json https://huggingface.co/bert-base-uncased/resolve/main/config.json\n",
    "!wget -q -O params/bert_base/vocab.txt https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt\n",
    "\n",
    "# 6. Generate Data Splits\n",
    "if not os.path.exists(\"./data/SST-2/bal/0\"):\n",
    "    print(\"Generating Data Splits...\")\n",
    "    !python setup_experiments.py\n",
    "else:\n",
    "    print(\"Data already generated.\")\n",
    "\n",
    "print(\"SETUP COMPLETE! Please run Cell 2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68329bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 2: ADVANCED TRAINING ENGINE (Scheduler + Smooth Queue)\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import collections\n",
    "from transformers import BertTokenizer, BertConfig, TFBertModel\n",
    "from pt_modeler import ConstructPtModeler\n",
    "from scipy.special import softmax\n",
    "\n",
    "# 1. Data Loader\n",
    "def load_local_data(task, data_path, tokenizer, max_len, val_ratio):\n",
    "    base_path = f\"./data/{task}/{data_path}\"\n",
    "\n",
    "    def process_file(filename, has_label=True):\n",
    "        filepath = os.path.join(base_path, filename)\n",
    "        if not os.path.exists(filepath) and \"test_with_gold\" in filename:\n",
    "            filepath = os.path.join(base_path, \"test.tsv\")\n",
    "        if not os.path.exists(filepath): return None, None\n",
    "\n",
    "        try: df = pd.read_csv(filepath, sep='\\t', header=0)\n",
    "        except: return None, None\n",
    "\n",
    "        text_col = df.columns[0]\n",
    "        for candidate in ['sentence', 'text', 'review']:\n",
    "            if candidate in df.columns: text_col = candidate; break\n",
    "\n",
    "        label_col = None\n",
    "        if has_label:\n",
    "            for candidate in ['label', 'target']:\n",
    "                if candidate in df.columns: label_col = candidate; break\n",
    "            if label_col is None and len(df.columns) > 1: label_col = df.columns[1]\n",
    "\n",
    "        sentences = df[text_col].astype(str).tolist()\n",
    "        encodings = tokenizer(sentences, truncation=True, padding='max_length', max_length=max_len, return_tensors='np')\n",
    "        x = [encodings['input_ids'], encodings['token_type_ids'], encodings['attention_mask']]\n",
    "        y = df[label_col].values if (has_label and label_col) else None\n",
    "        return x, y\n",
    "\n",
    "    x_train, y_train = process_file(\"labeled.tsv\", True)\n",
    "    x_unlab, _       = process_file(\"unlabeled.tsv\", False)\n",
    "    x_test, y_test   = process_file(\"test_with_gold.tsv\", True)\n",
    "\n",
    "    if x_train is None: return None\n",
    "\n",
    "    if val_ratio > 0:\n",
    "        split_at = int(len(x_train[0]) * (1 - val_ratio))\n",
    "        x_val = [arr[split_at:] for arr in x_train]\n",
    "        x_train_new = [arr[:split_at] for arr in x_train]\n",
    "        y_val = y_train[split_at:]\n",
    "        y_train_new = y_train[:split_at]\n",
    "        return {'x_train': x_train_new, 'y_train': y_train_new, 'x_val': x_val, 'y_val': y_val, 'x_test': x_test, 'y_test': y_test, 'x_unlab': x_unlab}\n",
    "    else:\n",
    "        return {'x_train': x_train, 'y_train': y_train, 'x_val': x_test, 'y_val': y_test, 'x_test': x_test, 'y_test': y_test, 'x_unlab': x_unlab}\n",
    "\n",
    "# 2. Config Class\n",
    "class Args:\n",
    "    def __init__(self, mode, val_ratio, seed):\n",
    "        self.task = 'SST-2'; self.data_path = 'bal/0'; self.seed = seed\n",
    "        self.pt_model_checkpoint = './params/bert_base/'\n",
    "        self.max_seq_length = 64\n",
    "        # Slightly higher start because we decay down\n",
    "        self.learning_rate = 3e-5\n",
    "        self.drop_rate = 0.2; self.epochs = 15; self.batch_size = 32\n",
    "        self.patience = 5; self.val_ratio = val_ratio; self.n_que = 5\n",
    "        self.word_freeze = False; self.class_num = 2; self.mode = mode\n",
    "\n",
    "# 3. Training Engine\n",
    "def train_engine(experiment_name, mode='combined', val_ratio=0.0, seed=42):\n",
    "    print(f\"\\nSTARTING: {experiment_name} | Mode: {mode} | Seed: {seed}\")\n",
    "\n",
    "    args = Args(mode, val_ratio, seed)\n",
    "    tf.random.set_seed(args.seed); np.random.seed(args.seed); random.seed(args.seed)\n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained(args.pt_model_checkpoint)\n",
    "    data = load_local_data(args.task, args.data_path, tokenizer, args.max_seq_length, args.val_ratio)\n",
    "    if data is None: return 0.0, 0.0, {}, None\n",
    "\n",
    "    # --- LR SCHEDULER ---\n",
    "    train_steps = (len(data['y_train']) // args.batch_size) * args.epochs\n",
    "    lr_schedule = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "        initial_learning_rate=args.learning_rate,\n",
    "        decay_steps=train_steps,\n",
    "        end_learning_rate=0.0,\n",
    "        power=1.0\n",
    "    )\n",
    "\n",
    "    modeler = ConstructPtModeler(TFBertModel, BertConfig, args.pt_model_checkpoint, args.max_seq_length, args.class_num, args.learning_rate, args.drop_rate, args.word_freeze)\n",
    "    model = modeler.build_model()\n",
    "\n",
    "    # Use scheduler in optimizer\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = {'accuracy': [], 'stop_metric': [], 'save_metric': []}\n",
    "\n",
    "    best_stop_metric = 999.0\n",
    "    best_save_metric_global = -999.0\n",
    "    best_model_weights = None\n",
    "    patience_counter = 0\n",
    "    s_class_queue = collections.deque([0.0] * args.n_que, maxlen=args.n_que)\n",
    "    c_u = np.array([0.5, 0.5])\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "        x_tr, y_tr = data['x_train'], data['y_train']\n",
    "        indices = np.arange(len(y_tr)); np.random.shuffle(indices)\n",
    "        for i in range(0, len(y_tr), args.batch_size):\n",
    "            batch_x = [arr[indices[i:i+args.batch_size]] for arr in x_tr]\n",
    "            model.train_on_batch(batch_x, y_tr[indices[i:i+args.batch_size]])\n",
    "\n",
    "        # Metrics\n",
    "        if mode == 'standard':\n",
    "             val_res = model.evaluate(data['x_val'], data['y_val'], verbose=0, batch_size=args.batch_size)\n",
    "             s_conf = val_res[0]\n",
    "             s_class = 0.0\n",
    "        else:\n",
    "            pred_u = model.predict(data['x_unlab'], batch_size=args.batch_size, verbose=0)\n",
    "            pred_probs = softmax(pred_u, axis=1)\n",
    "            conf_u = np.max(pred_probs, axis=1)\n",
    "            s_conf = np.mean(np.abs(conf_u - 0.9))\n",
    "            dist_u = np.mean(pred_probs, axis=0)\n",
    "            s_class = 1.0 - np.linalg.norm(dist_u - c_u)\n",
    "\n",
    "        # Logic\n",
    "        current_stop_val = s_conf\n",
    "        if mode == 'class': current_stop_val = -s_class\n",
    "\n",
    "        if current_stop_val < best_stop_metric:\n",
    "            best_stop_metric = current_stop_val\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        save_now = False\n",
    "        if mode == 'combined':\n",
    "            # SMOOTHING: Compare to Queue Average instead of Max to avoid spikes\n",
    "            queue_avg = sum(s_class_queue) / len(s_class_queue) if len(s_class_queue) > 0 else 0.0\n",
    "            if s_class > queue_avg:\n",
    "                save_now = True\n",
    "                print(f\"     New Best! S_Class={s_class:.4f} > Avg(Queue)={queue_avg:.4f}\")\n",
    "            s_class_queue.append(s_class)\n",
    "\n",
    "        elif mode == 'conf':\n",
    "             if s_conf == best_stop_metric: save_now = True\n",
    "        elif mode == 'class':\n",
    "             if s_class > best_save_metric_global:\n",
    "                 best_save_metric_global = s_class; save_now = True\n",
    "        elif mode == 'standard':\n",
    "             if s_conf == best_stop_metric: save_now = True\n",
    "\n",
    "        if patience_counter < args.patience:\n",
    "            if save_now: best_model_weights = model.get_weights()\n",
    "\n",
    "        test_acc = model.evaluate(data['x_test'], data['y_test'], verbose=0, batch_size=args.batch_size)[1]\n",
    "        history['accuracy'].append(test_acc)\n",
    "        history['stop_metric'].append(s_conf)\n",
    "        history['save_metric'].append(s_class)\n",
    "\n",
    "        print(f\"   Epoch {epoch+1}: Acc={test_acc:.4f} | Stop_Met={s_conf:.4f} | Save_Met={s_class:.4f}\")\n",
    "\n",
    "        if patience_counter >= args.patience:\n",
    "            print(\"   Early Stopping Triggered\")\n",
    "            break\n",
    "\n",
    "    if best_model_weights is not None:\n",
    "        print(\"   Restoring weights from the best checkpoint...\")\n",
    "        model.set_weights(best_model_weights)\n",
    "\n",
    "    final_acc = model.evaluate(data['x_test'], data['y_test'], verbose=0, batch_size=args.batch_size)[1]\n",
    "    avg_acc = np.mean(history['accuracy']) if history['accuracy'] else 0.0\n",
    "\n",
    "    return final_acc, avg_acc, history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c3ff9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 3: RUN EXPERIMENTS WITH SEED 42\n",
    "DEFAULT_SEED = 42\n",
    "\n",
    "print(\"EXPERIMENT 1/4: Original BUS-stop (Combined)\")\n",
    "acc_orig, avg_orig, hist_orig, model_combined = train_engine(\"Combined\", mode='combined', seed=DEFAULT_SEED)\n",
    "\n",
    "print(\"\\nEXPERIMENT 2/4: Confidence Similarity Only\")\n",
    "acc_conf, avg_conf, hist_conf, model_conf = train_engine(\"Conf Only\", mode='conf', seed=DEFAULT_SEED)\n",
    "\n",
    "print(\"\\nEXPERIMENT 3/4: Class Distribution Only\")\n",
    "acc_class, avg_class, hist_class, model_class = train_engine(\"Class Only\", mode='class', seed=DEFAULT_SEED)\n",
    "\n",
    "print(\"\\nEXPERIMENT 4/4: Standard Validation (Baseline)\")\n",
    "acc_std, avg_std, hist_std, model_std = train_engine(\"Standard\", mode='standard', val_ratio=0.1, seed=DEFAULT_SEED)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"{'Model Name':<20} | {'Final Test Acc':<15} | {'Avg Acc'}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Combined (BUS)':<20} | {acc_orig:.4f}          | {avg_orig:.4f}\")\n",
    "print(f\"{'Conf Only':<20} | {acc_conf:.4f}          | {avg_conf:.4f}\")\n",
    "print(f\"{'Class Only':<20} | {acc_class:.4f}          | {avg_class:.4f}\")\n",
    "print(f\"{'Standard (Val)':<20} | {acc_std:.4f}          | {avg_std:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c461ec83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 4: CONFUSION MATRICES PLOTTING\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_cm(model, title, ax=None):\n",
    "    # 1. Load Data \n",
    "    args = Args(mode='combined', val_ratio=0.0, seed=42)\n",
    "    tokenizer = BertTokenizer.from_pretrained(args.pt_model_checkpoint)\n",
    "    data = load_local_data(args.task, args.data_path, tokenizer, args.max_seq_length, args.val_ratio)\n",
    "\n",
    "    # 2. Predict\n",
    "    y_pred_logits = model.predict(data['x_test'], batch_size=args.batch_size, verbose=0)\n",
    "    y_pred = np.argmax(y_pred_logits, axis=1)\n",
    "    y_true = data['y_test']\n",
    "\n",
    "    # 3. Plot\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    if ax is None: fig, ax = plt.subplots(figsize=(5, 4))\n",
    "\n",
    "    # Heatmap \n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['Negative', 'Positive'],\n",
    "                yticklabels=['Negative', 'Positive'],\n",
    "                ax=ax, cbar=False)\n",
    "\n",
    "    # Axis Labels & Title\n",
    "    ax.set_title(f'{title}\\nAccuracy: {np.mean(y_true == y_pred):.1%}', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('True Label', fontsize=10)\n",
    "    ax.set_xlabel('Predicted Label', fontsize=10)\n",
    "\n",
    "# Setup Grid\n",
    "fig, axes = plt.subplots(1, 4, figsize=(24, 5))\n",
    "\n",
    "# Plot all 4 models\n",
    "plot_cm(model_combined, \"Combined (BUS)\", ax=axes[0])\n",
    "plot_cm(model_conf, \"Conf Only\", ax=axes[1])\n",
    "plot_cm(model_class, \"Class Only\", ax=axes[2])\n",
    "plot_cm(model_std, \"Standard (Val)\", ax=axes[3])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fd0c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 5: INDIVIDUAL TRAINING PLOTS (PLOT 1: ACCURACY, PLOT 2: STOP METRIC, PLOT 3: SAVE METRIC)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_individual_model(history, model_name, is_standard=False):\n",
    "    if not history or 'accuracy' not in history: return\n",
    "    epochs = range(1, len(history['accuracy']) + 1)\n",
    "\n",
    "    # Create a figure with 3 side-by-side plots\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "    # PLOT 1: Accuracy \n",
    "    axes[0].plot(epochs, history['accuracy'], 'b-o', linewidth=2, label='Test Accuracy')\n",
    "    axes[0].set_title(f\"{model_name}: Accuracy Curve\", fontweight='bold')\n",
    "    axes[0].set_xlabel(\"Epochs\")\n",
    "    axes[0].set_ylabel(\"Accuracy\")\n",
    "    axes[0].set_ylim(0.4, 1.0)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    axes[0].legend()\n",
    "\n",
    "    # PLOT 2: Stop Metric (The Brake) \n",
    "    metric_label = \"Val Loss\" if is_standard else \"S_conf (Stability)\"\n",
    "    color = \"red\"\n",
    "\n",
    "    axes[1].plot(epochs, history['stop_metric'], color=color, linestyle='--', marker='s', label=metric_label)\n",
    "    axes[1].set_title(f\"Stop Metric (Lower is Better)\", fontweight='bold')\n",
    "    axes[1].set_xlabel(\"Epochs\")\n",
    "    axes[1].set_ylabel(\"Metric Value\")\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "    # PLOT 3: Save Metric (The Judge)\n",
    "    save_label = \"Val Loss\" if is_standard else \"S_class (Distribution)\"\n",
    "    save_color = \"purple\" if is_standard else \"green\"\n",
    "\n",
    "    axes[2].plot(epochs, history['save_metric'], color=save_color, linestyle='-.', marker='^', label=save_label)\n",
    "    axes[2].set_title(f\"Save Metric (Selection Criteria)\", fontweight='bold')\n",
    "    axes[2].set_xlabel(\"Epochs\")\n",
    "    axes[2].set_ylabel(\"Metric Value\")\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.suptitle(f\"Training Dynamics: {model_name}\", fontsize=16, y=1.05)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"GENERATING LABELED PLOTS...\")\n",
    "\n",
    "if 'hist_orig' in locals(): plot_individual_model(hist_orig, \"Combined (BUS)\")\n",
    "if 'hist_conf' in locals(): plot_individual_model(hist_conf, \"Confidence Only\")\n",
    "if 'hist_class' in locals(): plot_individual_model(hist_class, \"Class Only\")\n",
    "if 'hist_std' in locals(): plot_individual_model(hist_std, \"Standard Baseline\", is_standard=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0ef5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 6: ROBUSTNESS CHECK WITH SEED = 35\n",
    "SEED_CHECK = 35\n",
    "\n",
    "print(f\"\\nSTARTING ROBUSTNESS CHECK WITH SEED {SEED_CHECK}...\")\n",
    "\n",
    "print(\"1. Training Combined...\")\n",
    "acc_orig_2, _, _, _ = train_engine(\"Combined\", mode='combined', seed=SEED_CHECK)\n",
    "print(\"2. Training Conf Only...\")\n",
    "acc_conf_2, _, _, _ = train_engine(\"Conf Only\", mode='conf', seed=SEED_CHECK)\n",
    "print(\"3. Training Class Only...\")\n",
    "acc_class_2, _, _, _ = train_engine(\"Class Only\", mode='class', seed=SEED_CHECK)\n",
    "\n",
    "print(\"\\n\" + \"=\"*40); print(f\"RESULTS FOR SEED {SEED_CHECK}\"); print(\"=\"*40)\n",
    "print(f\"{'Combined':<15} | {acc_orig_2:.4f}\")\n",
    "print(f\"{'Conf Only':<15} | {acc_conf_2:.4f}\")\n",
    "print(f\"{'Class Only':<15} | {acc_class_2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
